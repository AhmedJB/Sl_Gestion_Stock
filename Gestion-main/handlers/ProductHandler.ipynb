{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests as  req\n",
    "import os\n",
    "import csv\n",
    "pics_dir = 'pics'  # Replace with your actual 'pics' directory path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API_URL = \"http://127.0.0.1:8000/api/\"\n",
    "API_URL = \"https://bairhradiateur.ma/gestionapp/api/\"\n",
    "PATH_URL = \"product\"\n",
    "FINAL_URL =  API_URL + PATH_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOURN_MAPPING = {\n",
    "    \"Chine\" : 21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fournisseur': {'id': 38, 'name': 'japan', 'email': '', 'credit': 614168.0, 'phone': '', 'address': 'casablanca', 'date': '2021-10-11T16:03:47.139000Z'}, 'product': {'id': 1231, 'p_id': '4412601602718', 'name': 'GWADA NVV/9155', 'paid': 0.0, 'ptype': 'eau', 'price_vente': 1700.0, 'price_achat': 1150.0, 'quantity': 325}, 'options': {'id': 1247, 'metal': 'aluminium', 'type': '1R'}, 'images': [{'id': 211, 'image': '/media/products/GWADA.jpg', 'date': '2024-05-09T11:43:08.017398Z', 'product': 1231}]}\n"
     ]
    }
   ],
   "source": [
    "# get products\n",
    "def fetchProducts():\n",
    "    resp = req.get(API_URL + \"silentpd\")\n",
    "    data = resp.json()\n",
    "    res = []\n",
    "    for d in data:\n",
    "        res.append(d)\n",
    "    return res\n",
    "\n",
    "print(products[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login():\n",
    "    resp =  req.post(API_URL + \"token\", json = {\n",
    "        \"username\" : \"admin\",\n",
    "        \"password\" : \"bairhradiateur\"\n",
    "            })\n",
    "    print(resp.json())\n",
    "    return resp.json()[\"access\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refresh': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTcxNTM0MjcyMywiaWF0IjoxNzE1MjU2MzIzLCJqdGkiOiIwZmY0ZTQ2OWZjOGU0ZDZiYTgyNzNjOGY2NWFkY2ExNCIsInVzZXJfaWQiOjF9.86ELg_5P96Qq3lkBWCqq2a7pTmUoKrDKdnVpq6E1Lpk', 'access': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzE1MjU2NjIzLCJpYXQiOjE3MTUyNTYzMjMsImp0aSI6ImU1YzZlM2ZlNWM2YTRmODc4MTE5ZDg3ZTRkNTMzMTc3IiwidXNlcl9pZCI6MX0.HEd--8kEevzvzy1pE4rliPu6ATdqnIei6roqfUUnPSs'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(pics_dir):\n",
    "    \"\"\"Loops through subdirectories under 'pics_dir', extracts filenames without extensions,\n",
    "    and returns a list of dictionaries with 'path' and 'name' keys.\n",
    "\n",
    "    Args:\n",
    "        pics_dir (str): Path to the 'pics' directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing filenames and paths.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    for subdir, _, files in os.walk(pics_dir):\n",
    "        for filename in files:\n",
    "            # Extract filename without extension\n",
    "            base_filename = os.path.splitext(filename)[0]\n",
    "            # Construct full path\n",
    "            full_path = os.path.join(subdir, filename)\n",
    "\n",
    "            data.append({\n",
    "                \"path\": full_path,\n",
    "                \"name\": base_filename\n",
    "            })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_product(p_id):\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + token\n",
    "    }\n",
    "    resp = req.get(API_URL+\"modproduct/\"+p_id,headers=headers)\n",
    "    print(resp.status_code)\n",
    "    \n",
    "    if resp.status_code ==200:\n",
    "        print(\"deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_product(p_id,data):\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + token\n",
    "    }\n",
    "    resp = req.post(API_URL+\"modproduct/\"+p_id,json=data,headers=headers)\n",
    "    print(resp.status_code)\n",
    "    \n",
    "    if resp.status_code ==200:\n",
    "        print(\"updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(csv_file):\n",
    "    json_data = []\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        #next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            json_row = {\n",
    "                \"fournisseur\": FOURN_MAPPING[row[\"Fournisseur\"]],\n",
    "                \"product\": {\n",
    "                    \"name\": row[\"Nom du Produit\"],\n",
    "                    \"ptype\": row[\"Categorie\"],\n",
    "                    \"price_vente\": row[\"Prix Vente\"],\n",
    "                    \"price_achat\": row[\"Prix Vente\"],\n",
    "                    \"quantity\": row[\"Quantite\"],\n",
    "                    \"paid\": \"0\",\n",
    "                },\n",
    "                \"options\": {\n",
    "                    \"metal\": \"\",\n",
    "                    \"type\": row[\"Tube\"],\n",
    "                }\n",
    "            }\n",
    "            json_data.append(json_row)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter products \n",
    "def filter_data(data,products):\n",
    "    targets = [x[\"product\"][\"name\"] for x in data]\n",
    "    res = []\n",
    "    names = []\n",
    "    for p in products:\n",
    "        if p[\"product\"][\"name\"] in names:\n",
    "            print(\"duplicate\")\n",
    "            print(p)\n",
    "            if len(p[\"images\"]) == 0:\n",
    "                del_product(p[\"product\"][\"p_id\"])\n",
    "            else:\n",
    "                for i in range(len(res)):\n",
    "                    if res[i][\"product\"][\"name\"] == p[\"product\"]['name'] and len(res[i][\"images\"]) == 0:\n",
    "                        del_product(res[i][\"product\"][\"p_id\"])\n",
    "                        res[i] = p\n",
    "\n",
    "        elif p[\"product\"][\"name\"] in targets:\n",
    "            res.append(p)\n",
    "            names.append(p[\"product\"][\"name\"])\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token  = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzEzMzczMjI1LCJpYXQiOjE3MTMzNzI5MjUsImp0aSI6ImRjYzlhOThiZmJlMjRkMDk5OWNhNWIwOWY2MmY1MDhhIiwidXNlcl9pZCI6MX0.ZfnPec7f6UlLf94Q97SXbyP4akvLRRxD2QXlNDsC48k\"\n",
    "def submit_product(data):\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + token\n",
    "    }\n",
    "    resp = req.post(FINAL_URL,json=data,headers=headers)\n",
    "    if (resp.status_code == 200):\n",
    "        print(\"Saved in backend \" + data[\"product\"][\"name\"])\n",
    "    else:\n",
    "        print(\"Failed saving product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pics(images,data):\n",
    "    matched_data = []\n",
    "    unmatched_data = []\n",
    "\n",
    "    for img in images:\n",
    "        found = False\n",
    "        for d in data:\n",
    "            if d[\"product\"][\"name\"].lower() == img[\"name\"].lower() or img[\"name\"].lower() == d[\"product\"][\"name\"].lower():\n",
    "                matched_data.append({\n",
    "                    \"name\" : d[\"product\"][\"name\"],\n",
    "                    \"file\" : img[\"path\"],\n",
    "                    \"pid\" : d[\"product\"][\"p_id\"],\n",
    "                    \"id\" : d[\"product\"][\"id\"],\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        if not found:\n",
    "            unmatched_data.append(img)\n",
    "    return matched_data,unmatched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(matched_data):\n",
    "    grouped_data = {}\n",
    "    for m in matched_data:\n",
    "        if m[\"id\"] in grouped_data.keys():\n",
    "            grouped_data[m[\"pid\"]].append(m)\n",
    "        else:\n",
    "            grouped_data[m[\"pid\"]] = [m]\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadFile(d):\n",
    "    files = []\n",
    "    for img_d in d:\n",
    "        image_path = img_d[\"file\"]\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "            files.append((\"image\",(os.path.basename(image_path), image_data)))\n",
    "    data = {\"product\" : img_d[\"id\"]}\n",
    "    \n",
    "    url_ = API_URL + \"upload/\"\n",
    "    response = req.post(url_,files=files,data=data)\n",
    "\n",
    "    if response.status_code == 201:\n",
    "        print(\"uploaded\")\n",
    "    else:\n",
    "        print(\"Failed upload\")\n",
    "        print(d)\n",
    "        print(response.content.decode())\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleUpload(images,products):\n",
    "    matched_data,unmatched_data = match_pics(images,products)\n",
    "    print(len(matched_data))\n",
    "    print(len(unmatched_data))\n",
    "    for p in products:\n",
    "        print(p[\"product\"][\"name\"])\n",
    "    for u in matched_data:\n",
    "        print(u)\n",
    "    grouped_data = group_data(matched_data)\n",
    "    for k in grouped_data.keys():\n",
    "        try:\n",
    "            uploadFile(grouped_data[k])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            print(f\"Failed uploading for\")\n",
    "            print(grouped_data[k])\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    csv_file = 'out.csv'\n",
    "    json_data = csv_to_json(csv_file)\n",
    "    #filtered_json = [x for x in json_data if x[\"product\"][\"ptype\"] == \"Chauffage\"]\n",
    "    filtered_json = json_data\n",
    "    print(filtered_json)\n",
    "    \"\"\" for d in filtered_json:\n",
    "        submit_product(d) \"\"\"\n",
    "    filtered = filter_data(filtered_json,products)\n",
    "    print(len(filtered_json))\n",
    "    print(len(filtered))\n",
    "    images = extract_images(pics_dir)[1:]\n",
    "    handleUpload(images,filtered)\n",
    "\n",
    "    \n",
    "        #input(\"Continue\")\n",
    "    \n",
    "    # Write JSON data to a file\n",
    "    #with open('output.json', 'w') as json_file:\n",
    "    #    json.dump(json_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refresh': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTcxNTM0MzcwNSwiaWF0IjoxNzE1MjU3MzA1LCJqdGkiOiJjMWFmNTdkNjg1Yjg0NTM0YWVhZGRjNTlkMmM4ZDZiMCIsInVzZXJfaWQiOjF9.8VGE0JKzx4wLvMt32rcRw3OAwqw_dm9GqWwVXLikp_c', 'access': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzE1MjU3NjA1LCJpYXQiOjE3MTUyNTczMDUsImp0aSI6ImRiZWY4MDE2MjFjMTQyZTg4MjUxYTlkMGI2ZmEwY2M1IiwidXNlcl9pZCI6MX0.l-Ft_i4iof-S8dmV9naNBk398KqmOYQIXNjkrYUOEOc'}\n",
      "[{'fournisseur': 21, 'product': {'name': 'ISUZO NPR', 'ptype': 'Covers', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'REUNAULT', 'ptype': 'Covers', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'KIA PIKANTO', 'ptype': 'chauf', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'RANGE ROVER SPORT', 'ptype': 'chauf', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'HYUNDAI TUSCON', 'ptype': 'chauf', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'AUDI A3 LIMOUSINE', 'ptype': 'chauf', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'FIAT DUCTO', 'ptype': 'chauf', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}, {'fournisseur': 21, 'product': {'name': 'ACCENT', 'ptype': 'Covers', 'price_vente': '0', 'price_achat': '0', 'quantity': '0', 'paid': '0'}, 'options': {'metal': '', 'type': '0'}}]\n",
      "8\n",
      "8\n",
      "8\n",
      "67\n",
      "RANGE ROVER SPORT\n",
      "ISUZO NPR\n",
      "REUNAULT\n",
      "KIA PIKANTO\n",
      "HYUNDAI TUSCON\n",
      "AUDI A3 LIMOUSINE\n",
      "FIAT DUCTO\n",
      "ACCENT\n",
      "{'name': 'REUNAULT', 'file': 'pics/COVERS/REUNAULT.jpg', 'pid': '3575944139787', 'id': 2204}\n",
      "{'name': 'ISUZO NPR', 'file': 'pics/COVERS/ISUZO NPR.jpg', 'pid': '7294757859478', 'id': 2203}\n",
      "{'name': 'ACCENT', 'file': 'pics/COVERS/ACCENT.jpg', 'pid': '5306163248522', 'id': 2210}\n",
      "{'name': 'KIA PIKANTO', 'file': 'pics/LES_CHAUFFAGES/KIA PIKANTO.jpg', 'pid': '1713440822885', 'id': 2205}\n",
      "{'name': 'FIAT DUCTO', 'file': 'pics/LES_CHAUFFAGES/FIAT DUCTO.jpg', 'pid': '9200669523521', 'id': 2209}\n",
      "{'name': 'AUDI A3 LIMOUSINE', 'file': 'pics/LES_CHAUFFAGES/AUDI A3 LIMOUSINE.jpg', 'pid': '0097744113389', 'id': 2208}\n",
      "{'name': 'RANGE ROVER SPORT', 'file': 'pics/LES_CHAUFFAGES/RANGE ROVER SPORT.jpg', 'pid': '8260994084401', 'id': 2139}\n",
      "{'name': 'HYUNDAI TUSCON', 'file': 'pics/LES_CHAUFFAGES/HYUNDAI TUSCON.jpg', 'pid': '5365390123509', 'id': 2207}\n"
     ]
    }
   ],
   "source": [
    "products = fetchProducts()\n",
    "token = login()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filenames(pics_dir, output_file):\n",
    "    \"\"\"Loops through subdirectories under 'pics_dir', extracts filenames without extensions,\n",
    "    and writes them to a CSV file 'output_file'.\n",
    "\n",
    "    Args:\n",
    "        pics_dir (str): Path to the 'pics' directory.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Nom du Produit'])  # Write header row\n",
    "\n",
    "        for subdir, _, files in os.walk(pics_dir):\n",
    "            for filename in files:\n",
    "                # Extract filename without extension\n",
    "                base_filename = os.path.splitext(filename)[0]\n",
    "                writer.writerow([base_filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_filenames(\"pics\",\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
